---
title: "Assignment 3 - Causal inference"
author: "RF"
date: "2/5/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Assignment 3 - Exploring causal inference issues

In this assignment we explore some issues related to multiple regressions (regressions with more than one predictor), and inferred (causal) relations between variables. N.B. the data is simulated (to make sure I know the actual mechanism generating it), but it's based on a real study. So bear with a longish introduction to get into the details of what we are doing and why it is important.

### Altercentric intrusion in schizophrenia

People with schizophrenia often report altered control and distinction of self-other representations: intrusive thoughts, hearing of voices, delusions of mind reading, paranoia, etc (a substantial portion of the psychotic symptoms experienced in schizophrenia). These have been variously attributed to hypermentalizing (over attribution of mental states to others), social impairment (over preoccupation with own thought processes), hyper socialization (inability to inhibit information from others), etc.

The current study investigates 1) whether schizophrenia is indeed related to altered control and distinction of self-other representations, in particular altercentric intrusions (inability to inhibit social information), and 2) whether these are related to the relevant psychotic symptoms. N.B. the actual study also investigates egocentric intrusion, do check the papers below if interested.

The task is a slightly modified version of this: https://www.ncbi.nlm.nih.gov/pubmed/20731512 You look at a picture with some dots visible to you, as well as with a different person with a different set of dots visible to them. The number of dots you see and that the other sees can be the same (congruent condition) or not (incongruent condition). You are tasked to indicate whether a given number (e.g. 3) matches the number of dots you see (and the dots visible to the other person are irrelevant to the task).


The tasks investigates altercentric intrusion: will your reaction time change according to whether the other person is seeing the same amount of dots as you, or not? The idea is that if you correctly inhibit social information, your reaction time should not change, as the information about the other person is not relevant. On the contrary, if you nevertheless use task irrelevant social information, you'll be slower at indicating whether 3 is the right number of dots when the other person sees a different amount of dots than you (conflicting information).
The bigger the difference between RTs in the congruent and incongruent condition the bigger the altercentric intrusion effect.

For each participant you have 6 variables: 1) ID, 2) AltercentricIntrusion (continuous score), 3) Diagnosis (schizophrenia vs. control), 4) VoiceHearing (severity of voice hearing symptoms, continuous score of the severity of the symptom as measured by a clinician), 5) MindReading (severity of delusions of mind reading, continuous score of the severity of the symptom as measured by a clinician); 6) Apathy (severity of lack of motivation in taking care of oneself, from washing to showing up at work, continuous score of the severity of the symptom as measured by a clinician).

The research questions you have to answer are the following:

## First part

### Q1.1) Does schizophrenia involved altercentric intrusion? Define model and priors. Test the implications of your priors (prior predictive checks) and if needed adjust them. Run the model. Test the quality of the fitted model (posterior predictive checks). Assess the evidence in favor of an increased altercentric intrusion in schizophrenia. Report the model and the results, including plots.

```{r}
pacman::p_load(tidyverse, brms)

# Prepare the data

d <- read_csv("Ass3.csv")
summary(d)

d$Diagnosis <- plyr::revalue(as.character(d$Diagnosis), 
                             c("0"="Controls", "1"="Schizophrenia"))

d <- d %>%
  mutate(
    ID = as.factor(ID),
    Diagnosis = as.factor(Diagnosis)
  )

# Define the bayesian formula
AltercentricDiagnosis_f0 <- bf(
  AltercentricIntrusion ~ 1 + Diagnosis
)

AltercentricDiagnosis_f <- bf( # This is the one we use 
  AltercentricIntrusion ~ 0 + Diagnosis
)

# Design the priors
get_prior(AltercentricDiagnosis_f0, family = gaussian, d)
get_prior(AltercentricDiagnosis_f, family = gaussian, d)

priorDiagnosis <- c(
  prior(normal(4, 1), class = b),
  prior(normal(1, 2), class = sigma) # average error we expect
) 

# Test the priors

AltercentricDiagnosis_PriorCheck_m <- brm(
  formula = AltercentricDiagnosis_f,
  data = d,
  family = gaussian,
  prior = priorDiagnosis,
  sample_prior = "only" # meaning we don't take the data into account
)

# check how the prediction given only the priors and not the data will look like 
pp_check(AltercentricDiagnosis_PriorCheck_m, nsamples = 100)

## Fitting the model
AltercentricDiagnosis_m <- brm(
  formula = AltercentricDiagnosis_f,
  data = d,
  family = gaussian,
  prior = priorDiagnosis,
  sample_prior = T # only change, now we take data into account
)

# Posterior predictive check
pp_check(AltercentricDiagnosis_m, nsamples = 100)

## Check the model for warnings
AltercentricDiagnosis_m

# Hypothesis testing + updating check
plot(hypothesis(AltercentricDiagnosis_m,
           "DiagnosisSchizophrenia > DiagnosisControls")) # shows that the posterior has learned from the data 

hypothesis(AltercentricDiagnosis_m,
           "DiagnosisSchizophrenia > DiagnosisControls")

conditional_effects(AltercentricDiagnosis_m)

plot(conditional_effects(AltercentricDiagnosis_m), points=T)

```

The model indicates a credible difference in altercentric intrusion in the two groups supporting our hypothesis (b = 0.36, CIs = 0.16, 0.57, ER = 1332). Controls showed on average an altercentric intrusion effect of 3.86 (CIs 3.74, 3.98), and schizophrenia of 4.22 (CIs = 4.01, 4.43).
[Add plot of the effects]

SI
The model had no divergences, a Rhat of 1, and Effective Sample Sizes above 2000 for both Bulk and Tail.
[Add prior and posterior checks plots; add updating check plot]


### Q1.2) Is altercentric intrusion related to specific symptoms *in the patients*? Identify which of the symptoms could be relevant. Should you include more than one symptom? Build models, priors, predictive checks. Assess the evidence and report models and results, including plots. Discuss whether the results make sense.

(Riccardos suggestion: build the 3 models, with alercentric intrusion predicted from apathy, voice hearing and mindreading --> then build mulitple regression and assess evidence )

```{r}
# Filter out controls
d2 <- d %>% filter(Diagnosis == "Schizophrenia")

summary(d2)
# the mean of altercentric intrusion is about 4
sd(d2$AltercentricIntrusion)
# sd of altercentric intrusion is almost 1. therefore it make sense to put 1 as mean of sigma (because sigma is average error expected)

priorDiagnosis <- c(
  prior(normal(4, 1), class = b),
  prior(normal(1, 2), class = sigma) # average error we expect
) 


```

AI ~ Voice Hearing
```{r}

# Define the formula
AltercentricVoiceHearing_f0 <- bf(
  AltercentricIntrusion ~ 1 + VoiceHearing)

# Design the priors
get_prior(AltercentricVoiceHearing_f0, family = gaussian, d2) # continious variable

priorVoiceHearing <- c(
  prior(normal(3.5, 1), class = Intercept), # for intercept. what we believe is AI when voice hearing = 0.
  prior(normal(0.5,1), class = b), # for beta
  prior(normal(1, 2), class = sigma) # for uncertinty
)

# Test the priors
AltercentricVoiceHearing_PriorCheck_m <- brm(
  formula = AltercentricVoiceHearing_f0,
  data = d2,
  family = gaussian,
  prior = priorVoiceHearing,
  sample_prior = "only") # dont take data into account


# check how the prediction given only the priors and not the data will look like 
pp_check(AltercentricVoiceHearing_PriorCheck_m, nsamples = 100)
# the light blue are samplesbased on the priors. The balck one is the actual data - so we can see how well it fits.



## Fitting the model
AltercentricVoiceHearing_m <- brm(
  formula = AltercentricVoiceHearing_f0,
  data = d2,
  family = gaussian,
  prior = priorVoiceHearing,
  sample_prior = T # only change, now we take data into account
)

# Posterior predictive check
pp_check(AltercentricVoiceHearing_m, nsamples = 100)

## Check the model for warnings
AltercentricVoiceHearing_m

```

AI ~ Apathy
```{r}
# Define the formula
AltercentricApathy_f <- bf(
  AltercentricIntrusion ~ 1 + Apathy)


# Design the priors
get_prior(AltercentricApathy_f, family = gaussian, d2)

priorApathy <- c(
  prior(normal(3.5, 1), class = Intercept),
  prior(normal(0.5, 1), class = b),
  prior(normal(1, 2), class = sigma) # average error we expect
) 


# Test the priors
AltercentricApathy_PriorCheck_m <- brm(
  formula = AltercentricApathy_f,
  data = d2,
  family = gaussian,
  prior = priorApathy,
  sample_prior = "only" # meaning we don't take the data into account
)

# check how the prediction given only the priors and not the data will look like 
pp_check(AltercentricApathy_PriorCheck_m, nsamples = 100)




## Fitting the model
AltercentricApathy_m <- brm(
  formula = AltercentricApathy_f,
  data = d2,
  family = gaussian,
  prior = priorApathy,
  sample_prior = T # only change, now we take data into account
)

# Posterior predictive check
pp_check(AltercentricApathy_m, nsamples = 100)

## Check the model for warnings
AltercentricApathy_m


```
 
AI ~ Mind Reading
```{r}


# Define the formula
AltercentricMindReading_f <- bf(
  AltercentricIntrusion ~ 1 + MindReading)



# Design the priors
get_prior(AltercentricMindReading_f, family = gaussian, d2)

priorMindReading <- c(
  prior(normal(3.5, 1), class = Intercept),
  prior(normal(0.5, 1), class = b),
  prior(normal(1, 2), class = sigma) # average error we expect
) 


# Test the priors
AltercentricMindReading_PriorCheck_m <- brm(
  formula = AltercentricMindReading_f,
  data = d2,
  family = gaussian,
  prior = priorMindReading,
  sample_prior = "only" # meaning we don't take the data into account
)

# check how the prediction given only the priors and not the data will look like 
pp_check(AltercentricMindReading_PriorCheck_m, nsamples = 100)




## Fitting the model
AltercentricMindReading_m <- brm(
  formula = AltercentricMindReading_f,
  data = d2,
  family = gaussian,
  prior = priorMindReading,
  sample_prior = T # only change, now we take data into account
)

# Posterior predictive check
pp_check(AltercentricMindReading_m, nsamples = 100)

## Check the model for warnings
AltercentricMindReading_m





```



Multiple regression model

AI ~ MindReading + VoiceHearing
```{r}
# We mean center the 3 predictors 
d2 <- d2 %>% mutate(
  M_VoiceHearing = VoiceHearing - mean(VoiceHearing),
  M_Apathy = Apathy - mean(Apathy),
  M_MindReading = MindReading - mean(MindReading)
)


# Define the formula
MindVoice <- bf(
  AltercentricIntrusion ~ 1 + M_MindReading + M_VoiceHearing)


# Design the priors
get_prior(MindVoice, family = gaussian, d2)

prior_MindVoice <- c(
  prior(normal(4, 1), class = Intercept), # It is a good guess that when voice hearing and mind reading er mean, 
  prior(normal(0.1, 1), class = b),       # s? er AI ogs?
  prior(normal(1, 2), class = sigma) # average error we expect
) 


# Test the priors
MindVoice_m <- brm(
  formula = MindVoice,
  data = d2,
  family = gaussian,
  prior = prior_MindVoice,
  sample_prior = "only" # meaning we don't take the data into account
)


# check how the prediction given only the priors and not the data will look like 
pp_check(MindVoice_m, nsamples = 100)


## Fitting the model
MindReading_m2 <- brm(
  formula = MindVoice,
  data = d2,
  family = gaussian,
  prior = prior_MindVoice,
  sample_prior = T # only change, now we take data into account
)

# Posterior predictive check
pp_check(MindReading_m2, nsamples = 100)

## Check the model for warnings
MindReading_m2



```

AI ~ MindReading + Apathy
```{r}

# Define the formula
MindApathy <- bf(
  AltercentricIntrusion ~ 1 + M_MindReading + M_Apathy)


# Design the priors
get_prior(MindApathy, family = gaussian, d2)

prior_MindApathy <- c(
  prior(normal(4, 1), class = Intercept), # It is a good guess that when voice hearing and mind reading er mean, 
  prior(normal(0.1, 1), class = b, coef = M_MindReading),# s? er AI ogs?
  prior(normal(-0.5, 1), class = b, coef = M_Apathy),
  prior(normal(1, 2), class = sigma) # average error we expect
) 


# Test the priors
MindApathy_m <- brm(
  formula = MindApathy,
  data = d2,
  family = gaussian,
  prior = prior_MindApathy,
  sample_prior = "only" # meaning we don't take the data into account
)


# check how the prediction given only the priors and not the data will look like 
pp_check(MindApathy_m, nsamples = 100)


## Fitting the model
MindApathy_m2 <- brm(
  formula = MindApathy,
  data = d2,
  family = gaussian,
  prior = prior_MindApathy,
  sample_prior = T # only change, now we take data into account
)

# Posterior predictive check
pp_check(MindApathy_m2, nsamples = 100)

## Check the model for warnings
MindApathy_m2

```

AI ~ VoiceHearing + Apathy
```{r}
# Define the formula
VoiceApathy <- bf(
  AltercentricIntrusion ~ 1 + M_VoiceHearing + M_Apathy)


# Design the priors
get_prior(VoiceApathy, family = gaussian, d2)

prior_VoiceApathy <- c(
  prior(normal(4, 1), class = Intercept), # It is a good guess that when voice hearing and mind reading er mean, 
  prior(normal(0.1, 1), class = b, coef = M_VoiceHearing),# s? er AI ogs?
  prior(normal(-0.5, 1), class = b, coef = M_Apathy),
  prior(normal(1, 2), class = sigma) # average error we expect
) 


# Test the priors
VoiceApathy_m <- brm(
  formula = VoiceApathy,
  data = d2,
  family = gaussian,
  prior = prior_VoiceApathy,
  sample_prior = "only" # meaning we don't take the data into account
)


# check how the prediction given only the priors and not the data will look like 
pp_check(VoiceApathy_m, nsamples = 100)


## Fitting the model
VoiceApathy_m2 <- brm(
  formula = VoiceApathy,
  data = d2,
  family = gaussian,
  prior = prior_VoiceApathy,
  sample_prior = T # only change, now we take data into account
)

# Posterior predictive check
pp_check(VoiceApathy_m2, nsamples = 100)

## Check the model for warnings
VoiceApathy_m2

```

AI ~ VoiceHearing + MindReading + Apathy
```{r}

# Define the formula
VoiceMindApathy <- bf(
  AltercentricIntrusion ~ 1 + M_VoiceHearing + M_MindReading + M_Apathy)


# Design the priors
get_prior(VoiceMindApathy, family = gaussian, d2)

prior_VoiceMindApathy <- c(
  prior(normal(4, 1), class = Intercept), # It is a good guess that when voice hearing and mind reading er mean, 
  prior(normal(0.1, 1), class = b, coef = M_VoiceHearing),# s? er AI ogs?
  prior(normal(0.1, 1), class = b, coef = M_MindReading),
  prior(normal(-0.1, 1), class = b, coef = M_Apathy),
  prior(normal(1, 2), class = sigma) # average error we expect
) 


# Test the priors
VoiceMindApathy_m <- brm(
  formula = VoiceMindApathy,
  data = d2,
  family = gaussian,
  prior = prior_VoiceMindApathy,
  sample_prior = "only" # meaning we don't take the data into account
)


# check how the prediction given only the priors and not the data will look like 
pp_check(VoiceMindApathy_m, nsamples = 100)


## Fitting the model
VoiceMindApathy_m2 <- brm(
  formula = VoiceMindApathy,
  data = d2,
  family = gaussian,
  prior = prior_VoiceMindApathy,
  sample_prior = T # only change, now we take data into account
)

# Posterior predictive check
pp_check(VoiceMindApathy_m2, nsamples = 100)

## Check the model for warnings
VoiceMindApathy_m2


# Plot 
stanplot(VoiceMindApathy_m2)


```


Plot the predictors 
```{r}


# Hypothesis testing + updating check
#plot(hypothesis(VoiceMindApathy_m2,
#           "VoiceHearing > Intercept")) # shows that the posterior has learned from the data 

#hypothesis(AltercentricDiagnosis_m,
#           "DiagnosisSchizophrenia > DiagnosisControls")

conditional_effects(VoiceMindApathy_m2)

plot(conditional_effects(VoiceMindApathy_m2), points=T)




```



## Second part

Q2.1) However, we know that the diagnosis is based on symptom assessment: if the overall sum of symptoms is severe enough, the participant gets a diagnosis. In other words, by selecting the patients, and including the symptoms in the model we might have inadvertently introduced an issue in our inference. Do try to draw a causal graph (Directed Acyclical Graph) of the variables and compare it with the types of causal graphs presented in the slides. Discuss which biases you might have introduced.


Q2.2.) Redesign your analysis following the graph and report how the results change
```{r}
# Mena center all the data
d_m <- d %>% mutate(
  M_VoiceHearing = VoiceHearing - mean(VoiceHearing),
  M_MindReading = MindReading - mean(MindReading),
  M_Apathy = Apathy - mean(Apathy)
)


# Define the formula
VoiceMindApathy <- bf(
  AltercentricIntrusion ~ 1 + M_VoiceHearing + M_MindReading + M_Apathy)


# Design the priors
get_prior(VoiceMindApathy, family = gaussian, d_m)

prior_VoiceMindApathy <- c(
  prior(normal(4, 1), class = Intercept), # It is a good guess that when voice hearing and mind reading er mean, 
  prior(normal(0.1, 1), class = b, coef = M_VoiceHearing),# s? er AI ogs?
  prior(normal(0.1, 1), class = b, coef = M_MindReading),
  prior(normal(-0.1, 1), class = b, coef = M_Apathy),
  prior(normal(1, 2), class = sigma) # average error we expect
) 


# Test the priors
VoiceMindApathy_m3 <- brm(
  formula = VoiceMindApathy,
  data = d_m,
  family = gaussian,
  prior = prior_VoiceMindApathy,
  sample_prior = "only" # meaning we don't take the data into account
)


# check how the prediction given only the priors and not the data will look like 
pp_check(VoiceMindApathy_m3, nsamples = 100)


## Fitting the model
VoiceMindApathy_m4 <- brm(
  formula = VoiceMindApathy,
  data = d_m,
  family = gaussian,
  prior = prior_VoiceMindApathy,
  sample_prior = T # only change, now we take data into account
)

# Posterior predictive check
pp_check(VoiceMindApathy_m4, nsamples = 100)

## Check the model for warnings
VoiceMindApathy_m4


# Plot 
stanplot(VoiceMindApathy_m4)
conditional_effects(VoiceMindApathy_m4)
plot(conditional_effects(VoiceMindApathy_m4), points=T)



```




## Third part

These issues are very difficult to think through, and not knowing the causal mechanisms generating the data in advance makes our inferences even more unreliable. To explore these issues, I recommend using simulations. In other words, defining a "true" model, generating data from it and assessing what different analyses would lead you to infer (and therefore which biases they might introduce). You can find the code I used to simulate your data below.

Q3.1) Look through the code and identify whether the results you have match the underlying truth. Discuss what you have learned.

Q3.2) OPTIONAL: is this a general pattern? Try varying the parameters (e.g. correlation values) and assess whether the new dataset(s) leads to the same biases in your analysis.

